{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSlpaN6mbmun"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751031062865,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "2CzyGPioBUhL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBZo-t50bqZ-"
   },
   "source": [
    "# Detecting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1751031065065,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "f_a_vuFOB3IV",
    "outputId": "392c62b3-f228-4272-e195-846fdd210288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected header row (0-indexed): 3\n",
      "\n",
      "Columns in the DataFrame:\n",
      "Index(['ID', 'Website Name / Domain Name', 'Privacy Policy',\n",
      "       'Cookie Banner Deployed', 'User Consent Choices Honored',\n",
      "       'OneTrust Integration', 'Name of Third Party Integration / Tool',\n",
      "       'GPC Configuration', 'Geolocation Rules', 'Region',\n",
      "       'Average Monthly Traffic Volume', 'Level of Traffic Volume',\n",
      "       'Compliance Score', 'Level of Gap Quantity'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns as a Python list:\n",
      "['ID', 'Website Name / Domain Name', 'Privacy Policy', 'Cookie Banner Deployed', 'User Consent Choices Honored', 'OneTrust Integration', 'Name of Third Party Integration / Tool', 'GPC Configuration', 'Geolocation Rules', 'Region', 'Average Monthly Traffic Volume', 'Level of Traffic Volume', 'Compliance Score', 'Level of Gap Quantity']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_header_row(file_path, num_rows_to_check=50):\n",
    "\n",
    "    try:\n",
    "        temp_df = pd.read_excel(file_path, header=None, nrows=num_rows_to_check)\n",
    "\n",
    "        best_header_row_index = 0\n",
    "        max_score = -1\n",
    "        for i in range(len(temp_df)):\n",
    "            potential_header_series = temp_df.iloc[i]\n",
    "            numeric_check = pd.to_numeric(potential_header_series, errors='coerce')\n",
    "            non_numeric_count = numeric_check.isna().sum()\n",
    "            row_as_strings = potential_header_series.astype(str)\n",
    "            unique_non_empty_strings_count = row_as_strings[row_as_strings.str.strip() != ''].nunique()\n",
    "            current_score = (unique_non_empty_strings_count * 3) + non_numeric_count\n",
    "            if current_score > max_score:\n",
    "                max_score = current_score\n",
    "                best_header_row_index = i\n",
    "\n",
    "        print(f\"Detected header row (0-indexed): {best_header_row_index}\")\n",
    "        return best_header_row_index\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during header detection: {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "file_path = '../Sample Audit Report v1.xlsx'\n",
    "\n",
    "header_row_index = find_header_row(file_path)\n",
    "df = pd.read_excel(file_path, header=header_row_index)\n",
    "columns = df.columns\n",
    "\n",
    "print(\"\\nColumns in the DataFrame:\")\n",
    "print(columns)\n",
    "\n",
    "columns_list = columns.tolist()\n",
    "print(\"\\nColumns as a Python list:\")\n",
    "print(columns_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1751031066174,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "RvPCUpdZElW2",
    "outputId": "0bf84641-5c41-40b8-e47b-5a5236b2bbe3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Website Name / Domain Name</th>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th>Cookie Banner Deployed</th>\n",
       "      <th>User Consent Choices Honored</th>\n",
       "      <th>OneTrust Integration</th>\n",
       "      <th>Name of Third Party Integration / Tool</th>\n",
       "      <th>GPC Configuration</th>\n",
       "      <th>Geolocation Rules</th>\n",
       "      <th>Region</th>\n",
       "      <th>Average Monthly Traffic Volume</th>\n",
       "      <th>Level of Traffic Volume</th>\n",
       "      <th>Compliance Score</th>\n",
       "      <th>Level of Gap Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>testdomain.net</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>477782</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>93.5 out of 115</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>examplepage.org</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Not Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>173200</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>91 out of 115</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dummywebsite.info</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Not Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>130123</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>93 out of 115</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fakedata.biz</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>USA</td>\n",
       "      <td>31500</td>\n",
       "      <td>Moderate Volume</td>\n",
       "      <td>90.5 out of 115</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mocksite.co</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>30741</td>\n",
       "      <td>Moderate Volume</td>\n",
       "      <td>88 out of 115</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Website Name / Domain Name Privacy Policy Cookie Banner Deployed  \\\n",
       "0   1             testdomain.net            Yes                    Yes   \n",
       "1   2            examplepage.org            Yes                    Yes   \n",
       "2   3          dummywebsite.info            Yes                    Yes   \n",
       "3   4               fakedata.biz            Yes                    Yes   \n",
       "4   5                mocksite.co            Yes                    Yes   \n",
       "\n",
       "  User Consent Choices Honored  OneTrust Integration  \\\n",
       "0                           No  OneTrust Integration   \n",
       "1                           No  OneTrust Integration   \n",
       "2                           No  OneTrust Integration   \n",
       "3                           No  OneTrust Integration   \n",
       "4                           No  OneTrust Integration   \n",
       "\n",
       "  Name of Third Party Integration / Tool GPC Configuration Geolocation Rules  \\\n",
       "0                               OneTrust        Configured        Configured   \n",
       "1                               OneTrust    Not Configured        Configured   \n",
       "2                               OneTrust    Not Configured        Configured   \n",
       "3                               OneTrust        Configured        Configured   \n",
       "4                               OneTrust        Configured        Configured   \n",
       "\n",
       "   Region Average Monthly Traffic Volume Level of Traffic Volume  \\\n",
       "0  Global                         477782             High Volume   \n",
       "1  Global                         173200             High Volume   \n",
       "2  Global                         130123             High Volume   \n",
       "3     USA                          31500         Moderate Volume   \n",
       "4  Global                          30741         Moderate Volume   \n",
       "\n",
       "  Compliance Score Level of Gap Quantity  \n",
       "0  93.5 out of 115      Low Gap Quantity  \n",
       "1    91 out of 115      Low Gap Quantity  \n",
       "2    93 out of 115      Low Gap Quantity  \n",
       "3  90.5 out of 115      Low Gap Quantity  \n",
       "4    88 out of 115      Low Gap Quantity  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ext3653fRuIw"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El8_w3zjR0J7"
   },
   "source": [
    "## 1. Standardize column names: Remove leading/trailing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1751031067683,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "x3jl8CfmR65z",
    "outputId": "170e6610-c7fa-4a61-d88d-14d10ca76697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns stripped of whitespace.\n",
      "Current columns after stripping: ['ID', 'Website Name / Domain Name', 'Privacy Policy', 'Cookie Banner Deployed', 'User Consent Choices Honored', 'OneTrust Integration', 'Name of Third Party Integration / Tool', 'GPC Configuration', 'Geolocation Rules', 'Region', 'Average Monthly Traffic Volume', 'Level of Traffic Volume', 'Compliance Score', 'Level of Gap Quantity']\n",
      "Created a copy of the DataFrame for cleaning.\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "print(\"Columns stripped of whitespace.\")\n",
    "print(f\"Current columns after stripping: {df.columns.tolist()}\")\n",
    "df_cleaned = df.copy()\n",
    "print(\"Created a copy of the DataFrame for cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXNZdlTsSTw0"
   },
   "source": [
    "## 2. Handle 'N/A' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1751031068880,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "w-A2wIPzSWUY",
    "outputId": "b6c4634f-e932-4846-ea6b-8ee30c213341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common 'N/A' and empty string values replaced with NaN.\n"
     ]
    }
   ],
   "source": [
    "na_values_to_replace = ['N/A', 'n/a', 'NA', 'N.A.', 'not applicable', '-']\n",
    "for col in df_cleaned.select_dtypes(include='object').columns:\n",
    "        df_cleaned[col] = df_cleaned[col].astype(str)\n",
    "        df_cleaned[col] = df_cleaned[col].replace(na_values_to_replace, np.nan)\n",
    "        df_cleaned[col] = df_cleaned[col].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "print(\"Common 'N/A' and empty string values replaced with NaN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uESPDKNSgz8"
   },
   "source": [
    "## 3. Identify and filter 'Dead Links / Redirects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1751031069497,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "NTKD5QqARVrb",
    "outputId": "c1901c31-be9f-4392-9f67-22d01979e0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out inactive sites based on traffic-related columns: Average Monthly Traffic Volume, Level of Traffic Volume.\n",
      "Original rows: 150, Active rows: 117\n",
      "\n",
      "Active Sites DataFrame:\n",
      "(117, 14)\n"
     ]
    }
   ],
   "source": [
    "inactive_site_indicators = ['N/A - Dead Links / Redirects', 'Dead Links', 'Redirects']\n",
    "traffic_columns = [col for col in df_cleaned.columns if \"traffic\" in col.lower()]\n",
    "\n",
    "if traffic_columns:\n",
    "    active_mask = pd.Series([True] * len(df_cleaned), index=df_cleaned.index)\n",
    "\n",
    "    for col in traffic_columns:\n",
    "        col_inactive_mask = df_cleaned[col].astype(str).isin(inactive_site_indicators)\n",
    "        active_mask = active_mask & (~col_inactive_mask)\n",
    "\n",
    "    active_sites = df_cleaned[active_mask].copy()\n",
    "\n",
    "    print(f\"Filtered out inactive sites based on traffic-related columns: {', '.join(traffic_columns)}.\")\n",
    "    print(f\"Original rows: {len(df_cleaned)}, Active rows: {len(active_sites)}\")\n",
    "else:\n",
    "    print(f\"Warning: No columns containing 'traffic' (case-insensitive) found. Skipping filtering for active sites.\")\n",
    "    active_sites = df_cleaned.copy()\n",
    "\n",
    "print(\"\\nActive Sites DataFrame:\")\n",
    "print(active_sites.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCmOo-PMSthQ"
   },
   "source": [
    "## 4. Handle 'Any Score' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1751031070683,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "KC8gJAZrCN-t",
    "outputId": "07ee48a3-0222-466a-8491-c981dacac9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found score-related columns: ['Compliance Score']\n",
      "Cleaned 'Compliance Score' and converted to float (double).\n",
      "'Compliance Score' Dtype: float64\n",
      "\n",
      "--- Cleaned 'Score' columns preview ---\n",
      "     Compliance Score\n",
      "0           81.304348\n",
      "1           79.130435\n",
      "2           80.869565\n",
      "3           78.695652\n",
      "4           76.521739\n",
      "..                ...\n",
      "144         33.478261\n",
      "146         17.391304\n",
      "147         14.347826\n",
      "148         42.608696\n",
      "149         22.608696\n",
      "\n",
      "[117 rows x 1 columns]\n",
      "\n",
      "Data types after Score column cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117 entries, 0 to 149\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ID                                      117 non-null    int64  \n",
      " 1   Website Name / Domain Name              117 non-null    object \n",
      " 2   Privacy Policy                          117 non-null    object \n",
      " 3   Cookie Banner Deployed                  117 non-null    object \n",
      " 4   User Consent Choices Honored            117 non-null    object \n",
      " 5   OneTrust Integration                    117 non-null    object \n",
      " 6   Name of Third Party Integration / Tool  117 non-null    object \n",
      " 7   GPC Configuration                       117 non-null    object \n",
      " 8   Geolocation Rules                       117 non-null    object \n",
      " 9   Region                                  117 non-null    object \n",
      " 10  Average Monthly Traffic Volume          117 non-null    object \n",
      " 11  Level of Traffic Volume                 117 non-null    object \n",
      " 12  Compliance Score                        117 non-null    float64\n",
      " 13  Level of Gap Quantity                   117 non-null    object \n",
      "dtypes: float64(1), int64(1), object(12)\n",
      "memory usage: 13.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def parse_score_advanced(score_str):\n",
    "\n",
    "    if pd.isna(score_str) or str(score_str).strip() == '' or str(score_str).strip().lower() in [s.lower() for s in na_values_to_replace]:\n",
    "        return np.nan\n",
    "    s = str(score_str).strip().lower()\n",
    "\n",
    "    # Case 1: \"X out of Y\" format (e.g., \"75 out of 100\", \"15.5 out of 20\")\n",
    "    match_out_of = re.match(r'(\\d+(?:\\.\\d+)?)\\s*out of\\s*(\\d+(?:\\.\\d+)?)', s)\n",
    "    if match_out_of:\n",
    "        try:\n",
    "            numerator = float(match_out_of.group(1))\n",
    "            denominator = float(match_out_of.group(2))\n",
    "            if denominator != 0:\n",
    "                return (numerator / denominator) * 100.0\n",
    "            else:\n",
    "                return np.nan\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # Case 2: Percentage format (e.g., \"85.5 %\", \"92%\")\n",
    "    match_percent = re.match(r'(\\d+(?:\\.\\d+)?)\\s*%', s)\n",
    "    if match_percent:\n",
    "        try:\n",
    "            return float(match_percent.group(1)) * 1.0\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # Case 3: Normal numeric format (e.g., \"75\", \"120.5\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        pass # Fall through if conversion fails\n",
    "\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "score_columns = [col for col in active_sites.columns if 'score' in col.lower()]\n",
    "\n",
    "if score_columns:\n",
    "    print(f\"Found score-related columns: {score_columns}\")\n",
    "    for col_name in score_columns:\n",
    "        active_sites[col_name] = active_sites[col_name].astype(str)\n",
    "        active_sites[col_name] = active_sites[col_name].apply(parse_score_advanced)\n",
    "        print(f\"Cleaned '{col_name}' and converted to float (double).\")\n",
    "        print(f\"'{col_name}' Dtype: {active_sites[col_name].dtype}\")\n",
    "else:\n",
    "    print(\"No columns containing 'score' were found. Skipping cleaning for such columns.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Cleaned 'Score' columns preview ---\")\n",
    "print(active_sites[score_columns] if score_columns else active_sites)\n",
    "print(\"\\nData types after Score column cleaning:\")\n",
    "print(active_sites.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6ux_mWDWUZP"
   },
   "source": [
    "## 5. Normalize Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1751031072992,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "LDORq8y1WTWH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def normalize_col_name(col_name):\n",
    "    normalized = col_name.lower().strip()\n",
    "    normalized = normalized.replace(' / ', '/').replace(' ', '_')\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    sanitized = re.sub(r'[^\\w\\s-]', '_', filename.strip())\n",
    "    sanitized = re.sub(r'\\s+', '_', sanitized)\n",
    "    return sanitized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKh7bJp3WuRM"
   },
   "source": [
    "## 6. Remove Duplicate Websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1751031074002,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "Dl6E6-NUZUmZ",
    "outputId": "61a25c7f-2c9f-4754-c068-b463ea46d2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (117, 14)\n",
      "\n",
      "DataFrame shape after removing duplicates: (117, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame shape:\", active_sites.shape)\n",
    "active_sites = active_sites.drop_duplicates(subset=['Website Name / Domain Name'], keep='first')\n",
    "print(\"\\nDataFrame shape after removing duplicates:\", active_sites.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IN42JCQ2S5pj"
   },
   "source": [
    "## 7. General categorical column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1751031075691,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "51-uoklxDnVn",
    "outputId": "201d79fc-3f80-4c6d-a1d2-46ab9d91b760"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found potential categorical columns for cleaning: ['Website Name / Domain Name', 'Privacy Policy', 'Cookie Banner Deployed', 'User Consent Choices Honored', 'OneTrust Integration', 'Name of Third Party Integration / Tool', 'GPC Configuration', 'Geolocation Rules', 'Region', 'Average Monthly Traffic Volume', 'Level of Traffic Volume', 'Level of Gap Quantity']\n",
      "Cleaned 'Website Name / Domain Name' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Privacy Policy' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Cookie Banner Deployed' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'User Consent Choices Honored' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'OneTrust Integration' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Name of Third Party Integration / Tool' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'GPC Configuration' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Geolocation Rules' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Region' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Average Monthly Traffic Volume' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Level of Traffic Volume' by stripping whitespace and replacing empty strings with NaN.\n",
      "Cleaned 'Level of Gap Quantity' by stripping whitespace and replacing empty strings with NaN.\n",
      "\n",
      "--- Cleaned DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117 entries, 0 to 149\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ID                                      117 non-null    int64  \n",
      " 1   Website Name / Domain Name              117 non-null    object \n",
      " 2   Privacy Policy                          117 non-null    object \n",
      " 3   Cookie Banner Deployed                  117 non-null    object \n",
      " 4   User Consent Choices Honored            117 non-null    object \n",
      " 5   OneTrust Integration                    117 non-null    object \n",
      " 6   Name of Third Party Integration / Tool  117 non-null    object \n",
      " 7   GPC Configuration                       117 non-null    object \n",
      " 8   Geolocation Rules                       117 non-null    object \n",
      " 9   Region                                  117 non-null    object \n",
      " 10  Average Monthly Traffic Volume          117 non-null    object \n",
      " 11  Level of Traffic Volume                 117 non-null    object \n",
      " 12  Compliance Score                        117 non-null    float64\n",
      " 13  Level of Gap Quantity                   117 non-null    object \n",
      "dtypes: float64(1), int64(1), object(12)\n",
      "memory usage: 13.7+ KB\n",
      "\n",
      "--- Cleaned DataFrame Head ---\n",
      "   ID Website Name / Domain Name Privacy Policy Cookie Banner Deployed  \\\n",
      "0   1             testdomain.net            Yes                    Yes   \n",
      "1   2            examplepage.org            Yes                    Yes   \n",
      "2   3          dummywebsite.info            Yes                    Yes   \n",
      "3   4               fakedata.biz            Yes                    Yes   \n",
      "4   5                mocksite.co            Yes                    Yes   \n",
      "\n",
      "  User Consent Choices Honored  OneTrust Integration  \\\n",
      "0                           No  OneTrust Integration   \n",
      "1                           No  OneTrust Integration   \n",
      "2                           No  OneTrust Integration   \n",
      "3                           No  OneTrust Integration   \n",
      "4                           No  OneTrust Integration   \n",
      "\n",
      "  Name of Third Party Integration / Tool GPC Configuration Geolocation Rules  \\\n",
      "0                               OneTrust        Configured        Configured   \n",
      "1                               OneTrust    Not Configured        Configured   \n",
      "2                               OneTrust    Not Configured        Configured   \n",
      "3                               OneTrust        Configured        Configured   \n",
      "4                               OneTrust        Configured        Configured   \n",
      "\n",
      "   Region Average Monthly Traffic Volume Level of Traffic Volume  \\\n",
      "0  Global                         477782             High Volume   \n",
      "1  Global                         173200             High Volume   \n",
      "2  Global                         130123             High Volume   \n",
      "3     USA                          31500         Moderate Volume   \n",
      "4  Global                          30741         Moderate Volume   \n",
      "\n",
      "   Compliance Score Level of Gap Quantity  \n",
      "0         81.304348      Low Gap Quantity  \n",
      "1         79.130435      Low Gap Quantity  \n",
      "2         80.869565      Low Gap Quantity  \n",
      "3         78.695652      Low Gap Quantity  \n",
      "4         76.521739      Low Gap Quantity  \n"
     ]
    }
   ],
   "source": [
    "categorical_cols = active_sites.select_dtypes(include=['object']).columns\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\\nFound potential categorical columns for cleaning: {list(categorical_cols)}\")\n",
    "    for col_name in categorical_cols:\n",
    "        active_sites[col_name] = active_sites[col_name].astype(str).str.strip()\n",
    "        active_sites[col_name] = active_sites[col_name].replace(r'^\\s*$', np.nan, regex=True)\n",
    "        print(f\"Cleaned '{col_name}' by stripping whitespace and replacing empty strings with NaN.\")\n",
    "else:\n",
    "    print(\"\\nNo columns with 'object' dtype found to clean as categorical.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame Info ---\")\n",
    "active_sites.info()\n",
    "print(\"\\n--- Cleaned DataFrame Head ---\")\n",
    "print(active_sites.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtHM880dTDYM"
   },
   "source": [
    "## 8. General numerical column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1751031076925,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "iV9sNjuITIJh",
    "outputId": "785f8d0f-99b4-41b6-eb9f-0e517d0e1a5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to convert column 'Average Monthly Traffic Volume' to numeric. New Dtype: int64\n",
      "\n",
      "--- Cleaning Summary ---\n",
      "First 5 rows of the cleaned 'active_sites' DataFrame:\n",
      "   ID Website Name / Domain Name Privacy Policy Cookie Banner Deployed  \\\n",
      "0   1             testdomain.net            Yes                    Yes   \n",
      "1   2            examplepage.org            Yes                    Yes   \n",
      "2   3          dummywebsite.info            Yes                    Yes   \n",
      "3   4               fakedata.biz            Yes                    Yes   \n",
      "4   5                mocksite.co            Yes                    Yes   \n",
      "\n",
      "  User Consent Choices Honored  OneTrust Integration  \\\n",
      "0                           No  OneTrust Integration   \n",
      "1                           No  OneTrust Integration   \n",
      "2                           No  OneTrust Integration   \n",
      "3                           No  OneTrust Integration   \n",
      "4                           No  OneTrust Integration   \n",
      "\n",
      "  Name of Third Party Integration / Tool GPC Configuration Geolocation Rules  \\\n",
      "0                               OneTrust        Configured        Configured   \n",
      "1                               OneTrust    Not Configured        Configured   \n",
      "2                               OneTrust    Not Configured        Configured   \n",
      "3                               OneTrust        Configured        Configured   \n",
      "4                               OneTrust        Configured        Configured   \n",
      "\n",
      "   Region  Average Monthly Traffic Volume Level of Traffic Volume  \\\n",
      "0  Global                          477782             High Volume   \n",
      "1  Global                          173200             High Volume   \n",
      "2  Global                          130123             High Volume   \n",
      "3     USA                           31500         Moderate Volume   \n",
      "4  Global                           30741         Moderate Volume   \n",
      "\n",
      "   Compliance Score Level of Gap Quantity  \n",
      "0         81.304348      Low Gap Quantity  \n",
      "1         79.130435      Low Gap Quantity  \n",
      "2         80.869565      Low Gap Quantity  \n",
      "3         78.695652      Low Gap Quantity  \n",
      "4         76.521739      Low Gap Quantity  \n",
      "\n",
      "Data types of 'active_sites' DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117 entries, 0 to 149\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ID                                      117 non-null    int64  \n",
      " 1   Website Name / Domain Name              117 non-null    object \n",
      " 2   Privacy Policy                          117 non-null    object \n",
      " 3   Cookie Banner Deployed                  117 non-null    object \n",
      " 4   User Consent Choices Honored            117 non-null    object \n",
      " 5   OneTrust Integration                    117 non-null    object \n",
      " 6   Name of Third Party Integration / Tool  117 non-null    object \n",
      " 7   GPC Configuration                       117 non-null    object \n",
      " 8   Geolocation Rules                       117 non-null    object \n",
      " 9   Region                                  117 non-null    object \n",
      " 10  Average Monthly Traffic Volume          117 non-null    int64  \n",
      " 11  Level of Traffic Volume                 117 non-null    object \n",
      " 12  Compliance Score                        117 non-null    float64\n",
      " 13  Level of Gap Quantity                   117 non-null    object \n",
      "dtypes: float64(1), int64(2), object(11)\n",
      "memory usage: 13.7+ KB\n",
      "None\n",
      "\n",
      "Shape of the cleaned DataFrame (active_sites): (117, 14)\n"
     ]
    }
   ],
   "source": [
    "for col in active_sites.columns:\n",
    "        converted_col = pd.to_numeric(active_sites[col], errors='coerce')\n",
    "        if not converted_col.isnull().all() and converted_col.dtype != active_sites[col].dtype:\n",
    "            active_sites[col] = converted_col\n",
    "            print(f\"Attempted to convert column '{col}' to numeric. New Dtype: {active_sites[col].dtype}\")\n",
    "\n",
    "print(\"\\n--- Cleaning Summary ---\")\n",
    "print(\"First 5 rows of the cleaned 'active_sites' DataFrame:\")\n",
    "print(active_sites.head())\n",
    "print(\"\\nData types of 'active_sites' DataFrame:\")\n",
    "print(active_sites.info())\n",
    "print(f\"\\nShape of the cleaned DataFrame (active_sites): {active_sites.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1751031078046,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "Dfxx9USsRWUP",
    "outputId": "9d9b50a6-de5f-4051-ec02-e187ddf62e90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Website Name / Domain Name</th>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th>Cookie Banner Deployed</th>\n",
       "      <th>User Consent Choices Honored</th>\n",
       "      <th>OneTrust Integration</th>\n",
       "      <th>Name of Third Party Integration / Tool</th>\n",
       "      <th>GPC Configuration</th>\n",
       "      <th>Geolocation Rules</th>\n",
       "      <th>Region</th>\n",
       "      <th>Average Monthly Traffic Volume</th>\n",
       "      <th>Level of Traffic Volume</th>\n",
       "      <th>Compliance Score</th>\n",
       "      <th>Level of Gap Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>testdomain.net</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>477782</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>81.304348</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>examplepage.org</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Not Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>173200</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>79.130435</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dummywebsite.info</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Not Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>130123</td>\n",
       "      <td>High Volume</td>\n",
       "      <td>80.869565</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fakedata.biz</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>USA</td>\n",
       "      <td>31500</td>\n",
       "      <td>Moderate Volume</td>\n",
       "      <td>78.695652</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mocksite.co</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>OneTrust Integration</td>\n",
       "      <td>OneTrust</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Configured</td>\n",
       "      <td>Global</td>\n",
       "      <td>30741</td>\n",
       "      <td>Moderate Volume</td>\n",
       "      <td>76.521739</td>\n",
       "      <td>Low Gap Quantity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Website Name / Domain Name Privacy Policy Cookie Banner Deployed  \\\n",
       "0   1             testdomain.net            Yes                    Yes   \n",
       "1   2            examplepage.org            Yes                    Yes   \n",
       "2   3          dummywebsite.info            Yes                    Yes   \n",
       "3   4               fakedata.biz            Yes                    Yes   \n",
       "4   5                mocksite.co            Yes                    Yes   \n",
       "\n",
       "  User Consent Choices Honored  OneTrust Integration  \\\n",
       "0                           No  OneTrust Integration   \n",
       "1                           No  OneTrust Integration   \n",
       "2                           No  OneTrust Integration   \n",
       "3                           No  OneTrust Integration   \n",
       "4                           No  OneTrust Integration   \n",
       "\n",
       "  Name of Third Party Integration / Tool GPC Configuration Geolocation Rules  \\\n",
       "0                               OneTrust        Configured        Configured   \n",
       "1                               OneTrust    Not Configured        Configured   \n",
       "2                               OneTrust    Not Configured        Configured   \n",
       "3                               OneTrust        Configured        Configured   \n",
       "4                               OneTrust        Configured        Configured   \n",
       "\n",
       "   Region  Average Monthly Traffic Volume Level of Traffic Volume  \\\n",
       "0  Global                          477782             High Volume   \n",
       "1  Global                          173200             High Volume   \n",
       "2  Global                          130123             High Volume   \n",
       "3     USA                           31500         Moderate Volume   \n",
       "4  Global                           30741         Moderate Volume   \n",
       "\n",
       "   Compliance Score Level of Gap Quantity  \n",
       "0         81.304348      Low Gap Quantity  \n",
       "1         79.130435      Low Gap Quantity  \n",
       "2         80.869565      Low Gap Quantity  \n",
       "3         78.695652      Low Gap Quantity  \n",
       "4         76.521739      Low Gap Quantity  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1751031078652,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "Yhwg97WTaPaN",
    "outputId": "0b30d3ab-0762-4a0e-bfa0-c5e1183a95e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_sites.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOH_Qfplw9Ol"
   },
   "source": [
    "# PPT Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12354,
     "status": "ok",
     "timestamp": 1751031092689,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "x6aX8zprvcoq",
    "outputId": "d4e7018a-4ea5-43cd-9b38-438e1e2466eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\aditya\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: python-pptx in c:\\users\\aditya\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: Pillow>=3.3.2 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-pptx) (10.3.0)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-pptx) (3.2.5)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-pptx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\aditya\\anaconda3\\lib\\site-packages (from python-pptx) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install python-pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwrmXY9Qizdu"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1751031108149,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "NUSQDFDbe1Vt"
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import re\n",
    "from typing import Any, List, Optional, Tuple\n",
    "import random\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pptx import Presentation\n",
    "from pptx.dml.color import RGBColor\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.util import Emu, Pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3Py-PBQi5FL"
   },
   "source": [
    "### Bullet point integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1751031109189,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "Gm7TDpuQKQbr"
   },
   "outputs": [],
   "source": [
    "# --- Bullet Point Generation Functions ---\n",
    "def get_risk_counts(scores: pd.Series) -> Tuple[int, int, int]:\n",
    "    \"\"\"Return count of high, medium, low risk.\"\"\"\n",
    "    high = (scores < 60).sum()\n",
    "    medium = ((scores >= 60) & (scores < 90)).sum()\n",
    "    low = (scores >= 90).sum()\n",
    "    return high, medium, low\n",
    "\n",
    "def describe_distribution(series: pd.Series) -> str:\n",
    "    \"\"\"Describes the skewness of a numerical distribution.\"\"\"\n",
    "    skew = series.skew()\n",
    "    if skew > 0.5:\n",
    "        return \"right-skewed (most values below average)\"\n",
    "    elif skew < -0.5:\n",
    "        return \"left-skewed (most values above average)\"\n",
    "    else:\n",
    "        return \"normally distributed\"\n",
    "\n",
    "def generate_bullet_points_for_chart(\n",
    "    df: pd.DataFrame, col: str, chart_type: str\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate contextual bullet points based on data analysis.\"\"\"\n",
    "    bullet_points = []\n",
    "\n",
    "    nan_count_current_df = df[col].isnull().sum() + (df[col].astype(str).str.lower() == 'nan').sum()\n",
    "    total_records_current_df = len(df)\n",
    "    nan_pct_current_df = (nan_count_current_df / total_records_current_df) * 100 if total_records_current_df > 0 else 0\n",
    "\n",
    "    valid_data_filtered = df[col].dropna()\n",
    "    valid_data_filtered = valid_data_filtered[valid_data_filtered.astype(str).str.lower() != 'nan']\n",
    "\n",
    "\n",
    "    if chart_type == \"risk_distribution\" and not valid_data_filtered.empty:\n",
    "        high, medium, low = get_risk_counts(valid_data_filtered)\n",
    "        total = len(valid_data_filtered)\n",
    "\n",
    "        high_pct = (high / total) * 100 if total > 0 else 0\n",
    "        medium_pct = (medium / total) * 100 if total > 0 else 0\n",
    "        low_pct = (low / total) * 100 if total > 0 else 0\n",
    "\n",
    "        mean_score = valid_data_filtered.mean()\n",
    "        bullet_points = [\n",
    "            f\"Total {total} records analyzed with average score of {mean_score:.1f}\",\n",
    "            \"Risk score classification is based on percentage scores derived from the original scale: High risk (<60%), Medium risk (60-90%), Low risk (>=90%)\",\n",
    "            f\"High risk sites represent {high_pct:.1f}% ({high}) of total records\",\n",
    "            f\"Medium risk sites account for {medium_pct:.1f}% ({medium}) of total records\", # ADDED THIS LINE\n",
    "            f\"Low risk sites account for {low_pct:.1f}% ({low}) of total records\",\n",
    "  \n",
    "        ]\n",
    "    elif chart_type == \"score_distribution\" and not valid_data_filtered.empty:\n",
    "        mean, median, std = valid_data_filtered.mean(), valid_data_filtered.median(), valid_data_filtered.std()\n",
    "        dist_desc = describe_distribution(valid_data_filtered)\n",
    "        min_val, max_val = valid_data_filtered.min(), valid_data_filtered.max()\n",
    "        bullet_points = [\n",
    "            f\"Scores range from {min_val:.1f} to {max_val:.1f} with a mean of {mean:.1f}.\",\n",
    "            f\"Standard deviation of {std:.1f} shows {'high' if std > mean * 0.3 else 'moderate'} variability.\",\n",
    "            f\"The distribution is {dist_desc}.\",\n",
    "            f\"Median of {median:.1f} is {'close to' if abs(mean-median)<std*0.1 else 'distinct from'} the mean.\"\n",
    "        ]\n",
    "    elif chart_type == \"numerical_distribution\" and not valid_data_filtered.empty:\n",
    "        mean, median = valid_data_filtered.mean(), valid_data_filtered.median()\n",
    "        q25, q75 = valid_data_filtered.quantile(0.25), valid_data_filtered.quantile(0.75)\n",
    "\n",
    "\n",
    "        dead_links_count = nan_count_current_df\n",
    "        dead_links_pct = nan_pct_current_df\n",
    "\n",
    "        bullet_points = [\n",
    "            f\"The dataset has {len(valid_data_filtered)} valid entries and {dead_links_count} missing entries (about {dead_links_pct:.1f}%).\",\n",
    "            f\"The average value is {mean:.2f}, with a median of {median:.2f}.\",\n",
    "            f\"The 25th percentile is {q25:.2f}, and the 75th percentile is {q75:.2f}.\",\n",
    "            f\"The middle 50% of data lies between {q25:.2f} and {q75:.2f}.\"\n",
    "        ]\n",
    "    elif chart_type == \"categorical_pie\" or chart_type == \"categorical_bar\":\n",
    "\n",
    "        if nan_count_current_df > 0:\n",
    "            bullet_points.append(\n",
    "                f\"{nan_pct_current_df:.1f}% of entries ({nan_count_current_df} records) are missing or 'nan'.\"\n",
    "            )\n",
    "\n",
    "        if not valid_data_filtered.empty:\n",
    "            value_counts = valid_data_filtered.value_counts()\n",
    "            total_count_filtered = len(valid_data_filtered)\n",
    "\n",
    "\n",
    "            if not value_counts.empty:\n",
    "                top_category, top_count = value_counts.index[0], value_counts.iloc[0]\n",
    "                top_pct = (top_count / total_count_filtered) * 100\n",
    "\n",
    "                bullet_points.append(f\"The dataset contains {len(value_counts)} distinct categories across {total_count_filtered} valid records (excluding 'nan').\")\n",
    "                bullet_points.append(f\"The dominant category '{top_category}' has {top_count} occurrences ({top_pct:.1f}%).\")\n",
    "\n",
    "                if chart_type == \"categorical_pie\":\n",
    "                    bullet_points.append(f\"The distribution is {'relatively uniform' if top_pct < 40 else 'skewed towards a few dominant categories'}.\")\n",
    "                elif chart_type == \"categorical_bar\":\n",
    "                    top_10_count_filtered = value_counts.head(10).sum()\n",
    "                    top_10_make_up_pct = (top_10_count_filtered / total_count_filtered) * 100\n",
    "                    bullet_points.append(f\"The top 10 categories (excluding 'nan') make up {top_10_make_up_pct:.1f}% of all valid entries.\")\n",
    "\n",
    "\n",
    "                bullet_points.append(f\"The categories are {'spread out across many values' if len(value_counts) > total_count_filtered * 0.5 else 'mostly focused on a few values'}.\")\n",
    "            else:\n",
    "                if not bullet_points:\n",
    "                    bullet_points.append(f\"No valid (non-NaN) categorical data found for {col}.\")\n",
    "        else:\n",
    "            if not bullet_points:\n",
    "                bullet_points.append(f\"No valid (non-NaN) categorical data found for {col}.\")\n",
    "\n",
    "\n",
    "    return bullet_points\n",
    "\n",
    "\n",
    "def generate_hexbin_bullet_points(df: pd.DataFrame, x_col: str, y_col: str) -> List[str]:\n",
    "    \"\"\"Generates bullet points for a hexbin chart.\"\"\"\n",
    "    corr = df[x_col].corr(df[y_col])\n",
    "    return [\n",
    "        \"Darker hexagons indicate denser data regions, while lighter ones show sparser observations.\",\n",
    "        f\"A {'positive' if corr > 0 else 'negative' if corr < 0 else 'no'} linear trend exists (Pearson correlation coefficient: {corr:.2f}).\",\n",
    "        f\"{x_col} ranges from {df[x_col].min():.1f} to {df[x_col].max():.1f}, and {y_col} ranges from {df[y_col].min():.1f} to {df[y_col].max():.1f}.\"\n",
    "    ]\n",
    "\n",
    "def add_conclusion(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"Generate summary insights based on risk and volume columns.\"\"\"\n",
    "    volume_cols = [col for col in df.columns if \"volume\" in col.lower()]\n",
    "\n",
    "    str_volume_cols = [col for col in volume_cols if df[col].apply(lambda x: isinstance(x, str)).any()]\n",
    "    score_cols = [col for col in df.columns if \"score\" in col.lower()]\n",
    "    name_cols = [col for col in df.columns if any(keyword in col.lower() for keyword in [\"website\", \"domain\", \"site\", \"link\"])]\n",
    "\n",
    "    matching_rows = pd.DataFrame()\n",
    "    for vol_col in str_volume_cols:\n",
    "        for score_col in score_cols:\n",
    "\n",
    "            if pd.api.types.is_numeric_dtype(df[score_col]):\n",
    "                mask = df[vol_col].str.contains(\"high\", case=False, na=False) & (df[score_col] < 50)\n",
    "                filtered = df.loc[mask, name_cols]\n",
    "                matching_rows = pd.concat([matching_rows, filtered], ignore_index=True)\n",
    "\n",
    "    result = matching_rows.drop_duplicates().head(10)\n",
    "\n",
    "    if not result.empty and name_cols:\n",
    "        first_name_col = result.columns[0]\n",
    "\n",
    "        top_sites = result[first_name_col].dropna().astype(str).unique()[:9]\n",
    "        if len(top_sites) > 0:\n",
    "\n",
    "            if len(top_sites) > 1:\n",
    "                site_list = ', '.join(top_sites[:-1]) + f', and {top_sites[-1]}'\n",
    "            else:\n",
    "                site_list = top_sites[0]\n",
    "\n",
    "\n",
    "            score_col_name = score_cols[0].lower() if score_cols else \"score\"\n",
    "            volume_col_name = str_volume_cols[0].lower() if str_volume_cols else \"volume\"\n",
    "\n",
    "            return [\n",
    "                f\"The current dataset includes the following key columns: {', '.join(df.columns)}\",\n",
    "                f\"The sites {site_list} are considered high-risk given their low {score_col_name} despite having high {volume_col_name}.\"\n",
    "            ]\n",
    "    return [f\"The current dataset includes the following key columns: {', '.join(df.columns)}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk1TkJtXi9T2"
   },
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1751031110641,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "CUmFfB1qHmfm"
   },
   "outputs": [],
   "source": [
    "# --- Visualization Functions ---\n",
    "\n",
    "def plot_numerical_histogram(ax, series: pd.Series, col: str, clean_title: str):\n",
    "    \"\"\"Plots a histogram for numerical data.\"\"\"\n",
    "    mean_val, median_val, std_val = series.mean(), series.median(), series.std()\n",
    "    sns.histplot(series, kde=True, color='cornflowerblue', bins=30, ax=ax)\n",
    "    ax.axvline(mean_val, color='blue', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "    ax.axvline(median_val, color='red', linestyle='--', label=f'Median: {median_val:.2f}')\n",
    "    ax.axvline(mean_val + std_val, color='purple', linestyle=':', label=f'+-1 Std Dev: {std_val:.2f}')\n",
    "    ax.axvline(mean_val - std_val, color='purple', linestyle=':')\n",
    "    ax.set_title(f'Distribution of {clean_title}', fontsize=16, pad=20)\n",
    "    ax.set_xlabel(col, fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.legend()\n",
    "\n",
    "def plot_categorical_bar(ax, value_counts: pd.Series, col: str, clean_title: str):\n",
    "    \"\"\"Plots a bar chart for categorical data (top 10).\"\"\"\n",
    "    max_display_label_length = 20\n",
    "    sorted_index = value_counts.reset_index()\n",
    "    sorted_index.columns = ['label', 'count']\n",
    "    sorted_index['label'] = sorted_index['label'].astype(str)\n",
    "    sorted_index[\"label_length\"] = sorted_index[\"label\"].apply(len)\n",
    "    sorted_index[\"label_lower\"] = sorted_index[\"label\"].str.lower()\n",
    "    sorted_index = sorted_index.sort_values(\n",
    "        by=[\"count\", \"label_length\", \"label_lower\"],\n",
    "        ascending=[False, True, True]\n",
    "    ).drop(columns=\"label_lower\")\n",
    "\n",
    "    top_10_df = sorted_index.head(10).copy()\n",
    "\n",
    "    top_10_df[\"short_label\"] = top_10_df[\"label\"].apply(\n",
    "        lambda x: x if len(x) <= max_display_label_length else x[:max_display_label_length] + \"…\"\n",
    "    )\n",
    "\n",
    "    sns.barplot(\n",
    "        x=top_10_df[\"count\"],\n",
    "        y=top_10_df[\"short_label\"],\n",
    "        hue=top_10_df[\"short_label\"],\n",
    "        palette=\"Set2\",\n",
    "        orient=\"h\",\n",
    "        ax=ax,\n",
    "        legend=False\n",
    "    )\n",
    "    ax.set_title(f'Top 10 Most Frequent Values in {clean_title} (Excluding NaN)', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Count', fontsize=12)\n",
    "    ax.set_ylabel(col, fontsize=12)\n",
    "\n",
    "def identify_id_columns_by_pattern(df, patterns=None, verbose=False):\n",
    "    \n",
    "    if patterns is None:\n",
    "        patterns = [\n",
    "            r'\\b(?:id|no|num|number|key|serial|code|idx)\\b', \n",
    "            r'_id\\b',       \n",
    "            r'id_',          \n",
    "            r'sl_no',       \n",
    "            r'reference',  \n",
    "            r'ref\\b'        \n",
    "        ]\n",
    "    elif isinstance(patterns, str):\n",
    "        patterns = [patterns] \n",
    "\n",
    "    potential_id_columns = set()\n",
    "\n",
    "    for col in df.columns:\n",
    "        original_col_name = col\n",
    "        normalized_col_name = normalize_col_name(col)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n--- Analyzing column: '{original_col_name}' (Normalized: '{normalized_col_name}') ---\")\n",
    "\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, normalized_col_name, re.IGNORECASE):\n",
    "                potential_id_columns.add(original_col_name)\n",
    "                if verbose:\n",
    "                    print(f\"  - Flagged by: Column name matches pattern '{pattern}'\")\n",
    "                break\n",
    "\n",
    "    return list(potential_id_columns)\n",
    "\n",
    "\n",
    "def visualize_column_summary(\n",
    "    active_sites_df: pd.DataFrame\n",
    ") -> Tuple[List[Tuple[Any, str, List[str]]], List[str]]:\n",
    "\n",
    "    if not isinstance(active_sites_df, pd.DataFrame):\n",
    "        print(\"Error: Input is not a valid pandas DataFrame.\")\n",
    "        return [], []\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "    color_palette = ['#9370DB', '#FF6347', '#FFB300', '#32CD32', '#27AEEF']\n",
    "    \n",
    "    raw_cols_to_exclude = identify_id_columns_by_pattern(active_sites_df, verbose=True)\n",
    "    normalized_cols_to_exclude_set = {normalize_col_name(col) for col in raw_cols_to_exclude}\n",
    "    \n",
    "    score_keyword = 'score'\n",
    "    cols_for_viz = [col for col in active_sites_df.columns if normalize_col_name(col) not in normalized_cols_to_exclude_set]\n",
    "\n",
    "    \n",
    "    chart_data = []\n",
    "\n",
    "    for col in cols_for_viz:\n",
    "        clean_title = col.replace('_', ' ').replace('-', ' ').title()\n",
    "\n",
    "        # --- Handle Numerical Columns ---\n",
    "        if pd.api.types.is_numeric_dtype(active_sites_df[col]):\n",
    "            valid_numerical_data = active_sites_df[col].dropna()\n",
    "\n",
    "            valid_numerical_data = valid_numerical_data[valid_numerical_data.astype(str).str.lower() != 'nan']\n",
    "\n",
    "            if score_keyword in normalize_col_name(col):\n",
    "                if not valid_numerical_data.empty:\n",
    "                    # Pie chart: risk distribution for score columns\n",
    "                    fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
    "                    high, medium, low = get_risk_counts(valid_numerical_data)\n",
    "                    risk_counts = [high, medium, low]\n",
    "                    risk_labels = [\n",
    "                        f'High Risk', f'Medium Risk', f'Low Risk'\n",
    "                    ]\n",
    "\n",
    "\n",
    "                    colors_for_risk_pie = random.sample(color_palette, k=min(len(risk_labels), len(color_palette)))\n",
    "\n",
    "\n",
    "                    explode_values = [0.05 if i == 0 and high > 0 else 0 for i in range(len(risk_labels))]\n",
    "                    ax1.pie(\n",
    "                        risk_counts, labels=risk_labels, autopct='%1.1f%%', startangle=140,\n",
    "                        colors=colors_for_risk_pie, wedgeprops={'edgecolor': 'white'}, shadow=True, explode=explode_values\n",
    "                    )\n",
    "                    ax1.set_title(f'{clean_title} Risk Distribution', fontsize=16, pad=20)\n",
    "                    ax1.set_ylabel('')\n",
    "                    fig1.tight_layout()\n",
    "                    chart_data.append((\n",
    "                        fig1, f\"{clean_title} Risk Distribution\",\n",
    "                        generate_bullet_points_for_chart(active_sites_df, col, \"risk_distribution\")\n",
    "                    ))\n",
    "                    plt.close(fig1)\n",
    "\n",
    "                    # Histogram: score distribution\n",
    "                    fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "                    plot_numerical_histogram(ax2, valid_numerical_data, col, clean_title)\n",
    "                    fig2.tight_layout()\n",
    "                    chart_data.append((\n",
    "                        fig2, f\"{clean_title} Distribution\",\n",
    "                        generate_bullet_points_for_chart(active_sites_df, col, \"score_distribution\")\n",
    "                    ))\n",
    "                    plt.close(fig2)\n",
    "            else: # General numerical column\n",
    "                if not valid_numerical_data.empty:\n",
    "                    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                    plot_numerical_histogram(ax, valid_numerical_data, col, clean_title)\n",
    "                    fig.tight_layout()\n",
    "                    chart_data.append((\n",
    "                        fig, f\"{clean_title} Distribution\",\n",
    "                        generate_bullet_points_for_chart(active_sites_df, col, \"numerical_distribution\")\n",
    "                    ))\n",
    "                    plt.close(fig)\n",
    "\n",
    "        # --- Handle Categorical Columns ---\n",
    "        else:\n",
    "\n",
    "            non_null_series_filtered_for_plotting = active_sites_df[col].dropna()\n",
    "            non_null_series_filtered_for_plotting = non_null_series_filtered_for_plotting[non_null_series_filtered_for_plotting.astype(str).str.lower() != 'nan']\n",
    "\n",
    "            unique_count = non_null_series_filtered_for_plotting.nunique()\n",
    "\n",
    "            if unique_count == 0 or unique_count == len(non_null_series_filtered_for_plotting):\n",
    "\n",
    "                nan_count_for_bullet = active_sites_df[col].isnull().sum() + (active_sites_df[col].astype(str).str.lower() == 'nan').sum()\n",
    "                if nan_count_for_bullet == len(active_sites_df):\n",
    "                    chart_data.append((\n",
    "                        None, f\"{clean_title} Distribution (No valid data)\",\n",
    "                        generate_bullet_points_for_chart(active_sites_df, col, \"categorical_bar\")\n",
    "                    ))\n",
    "                continue\n",
    "\n",
    "            if unique_count <= 5:\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                value_counts = non_null_series_filtered_for_plotting.value_counts()\n",
    "                explode_values = [0.05] * len(value_counts)\n",
    "\n",
    "                colors_for_categorical_pie = random.sample(color_palette, k=min(len(value_counts), len(color_palette)))\n",
    "\n",
    "                ax.pie(\n",
    "                    value_counts, labels=value_counts.index.astype(str),\n",
    "                    autopct='%1.1f%%', startangle=140,\n",
    "                    colors=colors_for_categorical_pie, wedgeprops={'edgecolor': 'white'}, shadow=True, explode=explode_values\n",
    "                )\n",
    "                ax.set_title(f'Distribution of {clean_title} (excluding nan values)', fontsize=16, pad=20)\n",
    "                ax.set_ylabel('')\n",
    "                fig.tight_layout()\n",
    "                chart_data.append((\n",
    "                    fig, f\"{clean_title} Distribution\",\n",
    "                    generate_bullet_points_for_chart(active_sites_df, col, \"categorical_pie\")\n",
    "                ))\n",
    "                plt.close(fig)\n",
    "            else:\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                value_counts_for_bar_plot = non_null_series_filtered_for_plotting.value_counts()\n",
    "                plot_categorical_bar(ax, value_counts_for_bar_plot, col, clean_title)\n",
    "                fig.tight_layout()\n",
    "                chart_data.append((\n",
    "                    fig, f\"Top 10 {clean_title} Values\",\n",
    "                    generate_bullet_points_for_chart(active_sites_df, col, \"categorical_bar\")\n",
    "                ))\n",
    "                plt.close(fig)\n",
    "\n",
    "    # --- Hexbin plot (traffic vs score) ---\n",
    "    traffic_col, score_col = None, None\n",
    "    for col in active_sites_df.columns:\n",
    "        norm_col = normalize_col_name(col)\n",
    "        if pd.api.types.is_numeric_dtype(active_sites_df[col]):\n",
    "            if 'traffic' in norm_col:\n",
    "                traffic_col = col\n",
    "            elif 'score' in norm_col:\n",
    "                score_col = col\n",
    "\n",
    "    if traffic_col and score_col:\n",
    "        # Create a temporary DataFrame with only these two columns, dropping NaNs\n",
    "        df_hex = active_sites_df[[traffic_col, score_col]].dropna()\n",
    "        df_hex = df_hex[df_hex[traffic_col].astype(str).str.lower() != 'nan']\n",
    "        df_hex = df_hex[df_hex[score_col].astype(str).str.lower() != 'nan']\n",
    "\n",
    "        if not df_hex.empty:\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            hb = ax.hexbin(df_hex[traffic_col], df_hex[score_col], gridsize=30, cmap='viridis_r', mincnt=1)\n",
    "            cb = fig.colorbar(hb, ax=ax)\n",
    "            cb.set_label('Count')\n",
    "            ax.set_xlabel(traffic_col)\n",
    "            ax.set_ylabel(score_col)\n",
    "            ax.set_title(f'{traffic_col} vs {score_col} Hexbin Plot', fontsize=16, pad=20)\n",
    "            fig.tight_layout()\n",
    "            chart_title = f\"{traffic_col.replace('_',' ').title()} vs {score_col.replace('_',' ').title()} Relationship\"\n",
    "            chart_data.append((fig, chart_title, generate_hexbin_bullet_points(df_hex, traffic_col, score_col)))\n",
    "            plt.close(fig)\n",
    "\n",
    "    # Add overall conclusion\n",
    "    conclusion_bullets = add_conclusion(active_sites_df)\n",
    "\n",
    "    return chart_data, conclusion_bullets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVZnST_ijB1A"
   },
   "source": [
    "### PPT Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1751031112236,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "nxWffquSLtYZ"
   },
   "outputs": [],
   "source": [
    "# --- PPTX Creation Functions ---\n",
    "\n",
    "# Layout Constants\n",
    "TITLE_FONT_NAME = 'Times New Roman'\n",
    "TITLE_FONT_COLOR = RGBColor(112, 48, 160)\n",
    "TITLE_FONT_SIZE = Pt(32)\n",
    "BULLET_FONT_NAME = 'Times New Roman'\n",
    "BULLET_FONT_SIZE = Pt(20)\n",
    "BULLET_SPACE_AFTER = Pt(12)\n",
    "TOP_MARGIN_RATIO = 0.06\n",
    "BOTTOM_MARGIN_RATIO = 0.08\n",
    "LEFT_MARGIN_RATIO = 0.06\n",
    "RIGHT_MARGIN_RATIO = 0.04\n",
    "TITLE_HEIGHT_RATIO = 0.20\n",
    "CONTENT_HEIGHT_RATIO = 1 - TITLE_HEIGHT_RATIO\n",
    "TITLE_WIDTH_RATIO = 0.70\n",
    "TEXT_WIDTH_RATIO = 0.35\n",
    "IMAGE_WIDTH_RATIO = 0.65\n",
    "GAP_BETWEEN_TEXT_AND_IMAGE_RATIO = 0.005\n",
    "\n",
    "def bolden_values_paragraph(p, text):\n",
    "    \"\"\"Add bullet point with bolded numbers/percentages in the paragraph p.\"\"\"\n",
    "    pattern = re.compile(r\"(\\d[\\d,\\.]*%?|\\([\\d,\\.]+\\)|\\b[\\w\\-]+(?:\\.[\\w\\-]+)+\\b)\")\n",
    "    last = 0\n",
    "    for match in pattern.finditer(text):\n",
    "        if match.start() > last:\n",
    "            run = p.add_run()\n",
    "            run.text = text[last:match.start()]\n",
    "            run.font.bold = False\n",
    "            run.font.size = BULLET_FONT_SIZE\n",
    "            run.font.name = BULLET_FONT_NAME\n",
    "        run = p.add_run()\n",
    "        run.text = match.group(0)\n",
    "        run.font.bold = True\n",
    "        run.font.size = BULLET_FONT_SIZE\n",
    "        run.font.name = BULLET_FONT_NAME\n",
    "        last = match.end()\n",
    "    if last < len(text):\n",
    "        run = p.add_run()\n",
    "        run.text = text[last:]\n",
    "        run.font.bold = False\n",
    "        run.font.size = BULLET_FONT_SIZE\n",
    "        run.font.name = BULLET_FONT_NAME\n",
    "\n",
    "def add_custom_chart_slide(\n",
    "    prs: Presentation,\n",
    "    chart_fig,\n",
    "    chart_title: str,\n",
    "    bullet_points: List[str]\n",
    "):\n",
    "    slide_width, slide_height = prs.slide_width, prs.slide_height\n",
    "    usable_width = slide_width * (1 - LEFT_MARGIN_RATIO - RIGHT_MARGIN_RATIO)\n",
    "    usable_height = slide_height * (1 - TOP_MARGIN_RATIO - BOTTOM_MARGIN_RATIO)\n",
    "    usable_left = slide_width * LEFT_MARGIN_RATIO\n",
    "    usable_top = slide_height * TOP_MARGIN_RATIO\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[6])  # Blank layout\n",
    "\n",
    "    # Title\n",
    "    title_width = slide_width * TITLE_WIDTH_RATIO\n",
    "    title_left = (slide_width - title_width) / 2\n",
    "    title_top = usable_top\n",
    "    title_height = usable_height * TITLE_HEIGHT_RATIO\n",
    "    title_box = slide.shapes.add_textbox(\n",
    "        Emu(title_left), Emu(title_top), Emu(title_width), Emu(title_height)\n",
    "    )\n",
    "    tf = title_box.text_frame\n",
    "    tf.text = chart_title\n",
    "    tf.word_wrap = True\n",
    "    para = tf.paragraphs[0]\n",
    "    para.alignment = PP_ALIGN.CENTER\n",
    "    run = para.runs[0]\n",
    "    run.font.size = TITLE_FONT_SIZE\n",
    "    run.font.bold = True\n",
    "    run.font.name = TITLE_FONT_NAME\n",
    "    run.font.color.rgb = TITLE_FONT_COLOR\n",
    "\n",
    "    # Bullets\n",
    "    content_top = usable_top + usable_height * TITLE_HEIGHT_RATIO\n",
    "    content_height = usable_height * CONTENT_HEIGHT_RATIO\n",
    "    gap_width = usable_width * GAP_BETWEEN_TEXT_AND_IMAGE_RATIO\n",
    "    text_left = Emu(usable_left)\n",
    "    text_top = Emu(content_top)\n",
    "    text_width = Emu(usable_width * TEXT_WIDTH_RATIO - gap_width / 2)\n",
    "    text_height = Emu(content_height)\n",
    "    bullet_box = slide.shapes.add_textbox(text_left, text_top, text_width, text_height)\n",
    "    tf_bullets = bullet_box.text_frame\n",
    "    tf_bullets.word_wrap = True\n",
    "    for idx, txt in enumerate(bullet_points):\n",
    "        p = tf_bullets.paragraphs[0] if idx == 0 else tf_bullets.add_paragraph()\n",
    "        p.level = 0\n",
    "        p.space_after = BULLET_SPACE_AFTER\n",
    "        p.alignment = PP_ALIGN.LEFT\n",
    "        bolden_values_paragraph(p, u\"\\u2022 \" + txt)\n",
    "\n",
    "    # Image\n",
    "    image_left = Emu(usable_left + usable_width * TEXT_WIDTH_RATIO + gap_width / 2)\n",
    "    image_top = Emu(content_top)\n",
    "    image_width = Emu(usable_width * IMAGE_WIDTH_RATIO - gap_width / 2)\n",
    "    image_height = Emu(content_height)\n",
    "    img_buffer = io.BytesIO()\n",
    "    chart_fig.savefig(img_buffer, format='png', dpi=200, bbox_inches='tight')\n",
    "    img_buffer.seek(0)\n",
    "    plt.close(chart_fig)\n",
    "    img = Image.open(img_buffer)\n",
    "    img_width, img_height = img.size\n",
    "    max_width_px, max_height_px = int(image_width / 9525), int(image_height / 9525)\n",
    "    aspect = img_height / img_width\n",
    "    if max_height_px / aspect <= max_width_px:\n",
    "        final_height_px = max_height_px\n",
    "        final_width_px = int(final_height_px / aspect)\n",
    "    else:\n",
    "        final_width_px = max_width_px\n",
    "        final_height_px = int(final_width_px * aspect)\n",
    "    img_top_offset = int((max_height_px - final_height_px) / 2)\n",
    "    img_left_offset = int((max_width_px - final_width_px) / 2)\n",
    "    slide.shapes.add_picture(\n",
    "        img_buffer,\n",
    "        image_left + Emu(img_left_offset * 9525),\n",
    "        image_top + Emu(img_top_offset * 9525),\n",
    "        Emu(final_width_px * 9525),\n",
    "        Emu(final_height_px * 9525)\n",
    "    )\n",
    "\n",
    "async def build_presentation_with_charts(\n",
    "    template_path: str,\n",
    "    chart_figures_and_titles: List[Tuple[Any, str, List[str]]],\n",
    "    output_path: str,\n",
    "    insight_points: Optional[List[str]] = None\n",
    ") -> None:\n",
    "    prs = Presentation(template_path)\n",
    "    # Removing all but the first slide\n",
    "    for idx in range(len(prs.slides) - 1, 0, -1):\n",
    "        rId = prs.slides._sldIdLst[idx].rId\n",
    "        prs.slides._sldIdLst.remove(prs.slides._sldIdLst[idx])\n",
    "        prs.part.drop_rel(rId)\n",
    "    # Adding chart slides\n",
    "    for fig_obj, chart_title, chart_bullets in chart_figures_and_titles:\n",
    "        add_custom_chart_slide(prs, fig_obj, chart_title, chart_bullets)\n",
    "    # Insights slide\n",
    "    slide_width, slide_height = prs.slide_width, prs.slide_height\n",
    "    usable_width = slide_width * (1 - LEFT_MARGIN_RATIO - RIGHT_MARGIN_RATIO)\n",
    "    usable_height = slide_height * (1 - TOP_MARGIN_RATIO - BOTTOM_MARGIN_RATIO)\n",
    "    usable_left = slide_width * LEFT_MARGIN_RATIO\n",
    "    usable_top = slide_height * TOP_MARGIN_RATIO\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "    title_width = slide_width * TITLE_WIDTH_RATIO\n",
    "    title_left = (slide_width - title_width) / 2\n",
    "    title_top = usable_top\n",
    "    title_height = usable_height * TITLE_HEIGHT_RATIO\n",
    "    title_box = slide.shapes.add_textbox(\n",
    "        Emu(title_left), Emu(title_top), Emu(title_width), Emu(title_height)\n",
    "    )\n",
    "    tf = title_box.text_frame\n",
    "    tf.text = \"SUMMARY INSIGHTS\"\n",
    "    para = tf.paragraphs[0]\n",
    "    para.alignment = PP_ALIGN.CENTER\n",
    "    run = para.runs[0]\n",
    "    run.font.size = TITLE_FONT_SIZE\n",
    "    run.font.bold = True\n",
    "    run.font.name = TITLE_FONT_NAME\n",
    "    run.font.color.rgb = TITLE_FONT_COLOR\n",
    "    content_top = usable_top + usable_height * TITLE_HEIGHT_RATIO\n",
    "    content_height = usable_height * CONTENT_HEIGHT_RATIO\n",
    "    insight_left = Emu(usable_left + usable_width * 0.15)\n",
    "    insight_top = Emu(content_top)\n",
    "    insight_width = Emu(usable_width * 0.75)\n",
    "    insight_height = Emu(content_height)\n",
    "    insight_box = slide.shapes.add_textbox(insight_left, insight_top, insight_width, insight_height)\n",
    "    tf_bullets = insight_box.text_frame\n",
    "    tf_bullets.word_wrap = True\n",
    "    for idx, txt in enumerate(insight_points or []):\n",
    "        p = tf_bullets.paragraphs[0] if idx == 0 else tf_bullets.add_paragraph()\n",
    "        p.level = 0\n",
    "        p.space_after = BULLET_SPACE_AFTER\n",
    "        p.alignment = PP_ALIGN.LEFT\n",
    "        bolden_values_paragraph(p, u\"\\u2022 \" + txt)\n",
    "    # Thank you slide\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "    thank_left = Emu(usable_left + usable_width * 0.15)\n",
    "    thank_top = Emu(usable_top + usable_height * 0.35)\n",
    "    thank_width = Emu(usable_width * 0.7)\n",
    "    thank_height = Emu(usable_height * 0.3)\n",
    "    thank_box = slide.shapes.add_textbox(thank_left, thank_top, thank_width, thank_height)\n",
    "    tf = thank_box.text_frame\n",
    "    tf.text = \"THANK YOU\"\n",
    "    p = tf.paragraphs[0]\n",
    "    p.alignment = PP_ALIGN.CENTER\n",
    "    run = p.runs[0]\n",
    "    run.font.size = Pt(54)\n",
    "    run.font.bold = True\n",
    "    run.font.name = TITLE_FONT_NAME\n",
    "    run.font.color.rgb = RGBColor(128, 0, 128)\n",
    "    tf.word_wrap = True\n",
    "    prs.save(output_path)\n",
    "    print(f\"Presentation created at '{output_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jhGtNJwjFWR"
   },
   "source": [
    "### Main Exceution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 112,
     "status": "ok",
     "timestamp": 1751031113800,
     "user": {
      "displayName": "Sangsriti Sarkar",
      "userId": "17170911631457279590"
     },
     "user_tz": -330
    },
    "id": "V5kcESDLz3ri",
    "outputId": "a6fc1d53-e7b1-427e-f2b4-a9fa6cf8830c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerPoint integration task scheduled on existing event loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting chart generation ---\n",
      "\n",
      "\n",
      "--- Analyzing column: 'ID' (Normalized: 'id') ---\n",
      "  - Flagged by: Column name matches pattern '\\b(?:id|no|num|number|key|serial|code|idx)\\b'\n",
      "\n",
      "--- Analyzing column: 'Website Name / Domain Name' (Normalized: 'website_name/domain_name') ---\n",
      "\n",
      "--- Analyzing column: 'Privacy Policy' (Normalized: 'privacy_policy') ---\n",
      "\n",
      "--- Analyzing column: 'Cookie Banner Deployed' (Normalized: 'cookie_banner_deployed') ---\n",
      "\n",
      "--- Analyzing column: 'User Consent Choices Honored' (Normalized: 'user_consent_choices_honored') ---\n",
      "\n",
      "--- Analyzing column: 'OneTrust Integration' (Normalized: 'onetrust_integration') ---\n",
      "\n",
      "--- Analyzing column: 'Name of Third Party Integration / Tool' (Normalized: 'name_of_third_party_integration/tool') ---\n",
      "\n",
      "--- Analyzing column: 'GPC Configuration' (Normalized: 'gpc_configuration') ---\n",
      "\n",
      "--- Analyzing column: 'Geolocation Rules' (Normalized: 'geolocation_rules') ---\n",
      "\n",
      "--- Analyzing column: 'Region' (Normalized: 'region') ---\n",
      "\n",
      "--- Analyzing column: 'Average Monthly Traffic Volume' (Normalized: 'average_monthly_traffic_volume') ---\n",
      "\n",
      "--- Analyzing column: 'Level of Traffic Volume' (Normalized: 'level_of_traffic_volume') ---\n",
      "\n",
      "--- Analyzing column: 'Compliance Score' (Normalized: 'compliance_score') ---\n",
      "\n",
      "--- Analyzing column: 'Level of Gap Quantity' (Normalized: 'level_of_gap_quantity') ---\n",
      "\n",
      "--- Finished chart generation ---\n",
      "\n",
      "Presentation created at 'new_ppt.pptx'\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "async def main_execution(\n",
    "    active_sites: pd.DataFrame,\n",
    "    template_ppt_path: str = 'GT_TA.pptx',\n",
    "    output_ppt_path: str = 'new_ppt.pptx'\n",
    "):\n",
    "    print(\"\\n--- Starting chart generation ---\\n\")\n",
    "\n",
    "    chart_figures_and_titles, conclusion_points = visualize_column_summary(active_sites)\n",
    "    print(\"\\n--- Finished chart generation ---\\n\")\n",
    "    await build_presentation_with_charts(\n",
    "        template_ppt_path,\n",
    "        chart_figures_and_titles,\n",
    "        output_ppt_path,\n",
    "        conclusion_points\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        asyncio.ensure_future(main_execution(active_sites))\n",
    "        print(\"PowerPoint integration task scheduled on existing event loop.\")\n",
    "    else:\n",
    "        loop.run_until_complete(main_execution(active_sites))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
